{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Evaluating the LLM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import time\n",
    "import pandas as pd\n",
    "from llm import getChatChain\n",
    "from app import load_documents_into_database\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.evaluation import load_evaluator\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.evaluation import Criteria\n",
    "import re, json\n",
    "from typing import Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mistral(llm_model_name: str, db: Chroma) -> tuple:\n",
    "    \n",
    "    evaluator = load_evaluator(\"labeled_score_string\", criteria=\"correctness\", llm=Ollama(model=llm_model_name))\n",
    "    f = open(\"Stats.csv\",\"a\")\n",
    "    tempo = 0\n",
    "    chat = getChatChain(Ollama(model=llm_model_name), db)\n",
    "    df = pd.read_csv(\"evaluate.csv\")\n",
    "\n",
    "    print(\"\\n[INFO] Evaluating model: \", llm_model_name)\n",
    "    for index, row in df.iterrows():\n",
    "        inicio = time.time()\n",
    "\n",
    "        question = row['question']\n",
    "        reference_answer = row['answer']\n",
    "        model_answer = chat(question=question)\n",
    "        \n",
    "        fim = time.time()\n",
    "        tempo = round(float(fim - inicio),2)\n",
    "\n",
    "        try:\n",
    "            evaluation = evaluator.evaluate_strings(\n",
    "                prediction=model_answer,\n",
    "                reference=reference_answer,\n",
    "                input=question\n",
    "            )\n",
    "        except ValueError as e:\n",
    "            print(f\"ValueError: {e}\")\n",
    "            evaluation = str(e)  # Assign the exception message to evaluation\n",
    "\n",
    "        # Debugging print statement to inspect the evaluation output\n",
    "        print(f\"Evaluation output: {evaluation}\")\n",
    "\n",
    "        # Extract the score using regex\n",
    "        match = re.search(r'Rating: (\\d+)', evaluation)\n",
    "        if match:\n",
    "            score = int(match.group(1))\n",
    "        else:\n",
    "            print(f\"Invalid format for evaluation output: {evaluation}\")\n",
    "            continue\n",
    "\n",
    "        print(f'\\n[QUESTION] {question}')\n",
    "        print(f'[SCORE] {score}')\n",
    "        f.write(f\"{llm_model_name},{score},{tempo}\\n\")\n",
    "    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rating(evaluation: str) -> int:\n",
    "    \"\"\"\n",
    "    Extracts the rating number enclosed in single or double brackets from the evaluation string.\n",
    "    \"\"\"\n",
    "    match = re.search(r'Rating: \\[?\\[?(\\d+)\\]?\\]?', evaluation)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        print(f\"Invalid format for evaluation output: {evaluation}\")\n",
    "        return None\n",
    "\n",
    "def evaluate_llama2(llm_model_name: str, db: Chroma) -> tuple:\n",
    "    evaluator = load_evaluator(\"labeled_score_string\", criteria=\"correctness\", llm=Ollama(model=llm_model_name))\n",
    "    chat = getChatChain(Ollama(model=llm_model_name), db)\n",
    "    df = pd.read_csv(\"evaluate.csv\")\n",
    "\n",
    "    print(\"\\n[INFO] Evaluating model: \", llm_model_name)\n",
    "    with open(\"Stats.csv\", \"a\") as f:\n",
    "        for index, row in df.iterrows():\n",
    "            inicio = time.time()\n",
    "\n",
    "            question = row['question']\n",
    "            reference_answer = row['answer']\n",
    "            model_answer = chat(question=question)\n",
    "            \n",
    "            fim = time.time()\n",
    "            tempo = round(float(fim - inicio), 2)\n",
    "\n",
    "            try:\n",
    "                evaluation = evaluator.evaluate_strings(\n",
    "                    prediction=model_answer,\n",
    "                    reference=reference_answer,\n",
    "                    input=question\n",
    "                )\n",
    "            except ValueError as e:\n",
    "                print(f\"ValueError: {e}\")\n",
    "                evaluation = str(e)  # Assign the exception message to evaluation\n",
    "\n",
    "            # Debugging print statement to inspect the evaluation output\n",
    "            print(f\"Evaluation output: {evaluation}\")\n",
    "\n",
    "            # Convert the evaluation to a string if it is a dictionary\n",
    "            if isinstance(evaluation, dict):\n",
    "                evaluation = json.dumps(evaluation)\n",
    "\n",
    "            # Extract the rating using the new function\n",
    "            score = extract_rating(evaluation)\n",
    "            if score is None:\n",
    "                continue\n",
    "\n",
    "            print(f'\\n[QUESTION] {question}')\n",
    "            print(f'[SCORE] {score}')\n",
    "            f.write(f\"{llm_model_name},{score},{tempo}\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rating(evaluation: str) -> int:\n",
    "    \"\"\"\n",
    "    Extracts the rating number from the evaluation string.\n",
    "    It handles both single and double-bracketed formats.\n",
    "    \"\"\"\n",
    "    match = re.search(r'Rating: \\[?\\[?(\\d+)\\]?\\]?', evaluation)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        print(f\"Invalid format for evaluation output: {evaluation}\")\n",
    "        return None\n",
    "\n",
    "def evaluate_zephyr(llm_model_name: str, db: Chroma) -> tuple:\n",
    "    evaluator = load_evaluator(\"labeled_score_string\", criteria=\"correctness\", llm=Ollama(model=llm_model_name))\n",
    "    chat = getChatChain(Ollama(model=llm_model_name), db)\n",
    "    df = pd.read_csv(\"evaluate.csv\")\n",
    "\n",
    "    print(\"\\n[INFO] Evaluating model: \", llm_model_name)\n",
    "    with open(\"Stats.csv\", \"a\") as f:\n",
    "        for index, row in df.iterrows():\n",
    "            inicio = time.time()\n",
    "\n",
    "            question = row['question']\n",
    "            reference_answer = row['answer']\n",
    "            model_answer = chat(question=question)\n",
    "            \n",
    "            fim = time.time()\n",
    "            tempo = round(float(fim - inicio), 2)\n",
    "\n",
    "            try:\n",
    "                evaluation = evaluator.evaluate_strings(\n",
    "                    prediction=model_answer,\n",
    "                    reference=reference_answer,\n",
    "                    input=question\n",
    "                )\n",
    "            except ValueError as e:\n",
    "                print(f\"ValueError: {e}\")\n",
    "                evaluation = str(e)  # Assign the exception message to evaluation\n",
    "\n",
    "            # Debugging print statement to inspect the evaluation output\n",
    "            print(f\"Evaluation output: {evaluation}\")\n",
    "\n",
    "            # Convert the evaluation to a string if it is a dictionary\n",
    "            if isinstance(evaluation, dict):\n",
    "                evaluation = json.dumps(evaluation)\n",
    "\n",
    "            # Extract the rating using the updated function\n",
    "            score = extract_rating(evaluation)\n",
    "            if score is None:\n",
    "                continue\n",
    "\n",
    "            print(f'\\n[QUESTION] {question}')\n",
    "            print(f'[SCORE] {score}')\n",
    "            f.write(f\"{llm_model_name},{score},{tempo}\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents\n",
      "Loading .pdf files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:03<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading .md files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings and loading documents into Chroma\n",
      "\n",
      "[INFO] Evaluating model:  mistral\n",
      " I cannot answer that question with the provided research documents. The research only discusses muscle growth methods and warm-up exercises. There is no information about the number of parts in the human chest.ValueError: Invalid output:  Rating: 10\n",
      "\n",
      "Explanation: The assistant correctly acknowledged that it could not provide an answer to the question based on the available information, and did not attempt to provide a incorrect or misleading response.. Output must contain a double bracketed string                 with the verdict between 1 and 10.\n",
      "Evaluation output: Invalid output:  Rating: 10\n",
      "\n",
      "Explanation: The assistant correctly acknowledged that it could not provide an answer to the question based on the available information, and did not attempt to provide a incorrect or misleading response.. Output must contain a double bracketed string                 with the verdict between 1 and 10.\n",
      "\n",
      "[QUESTION] how many parts has the human chest?\n",
      "[SCORE] 10\n",
      "O Modelo demorou 48.99 segundos a gerar as respostas.\n"
     ]
    }
   ],
   "source": [
    "# Avaliação do Mistral segundo o Tempo, a Precisão e a Accuracy.\n",
    "inicio = time.time()\n",
    "db = load_documents_into_database(\"mistral\", \"nomic-embed-text\", \"../Final PDF Files\", True)\n",
    "evaluate_mistral(\"mistral\", db)\n",
    "fim = time.time()\n",
    "print(\"O Modelo demorou \" + str(round((fim-inicio), 2)) + \" segundos a gerar as respostas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents\n",
      "Loading .pdf files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:04<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading .md files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings and loading documents into Chroma\n",
      "\n",
      "[INFO] Evaluating model:  llama2\n",
      "Based on the provided research, the human chest has 4 parts:\n",
      "\n",
      "1. Pectoralis Major Muscle: This muscle is located in the chest area and is responsible for shoulder movement and breathing.\n",
      "2. Pectoralis Minor Muscle: This muscle is located beneath the pectoralis major muscle and helps to rotate the scapula and move the arm.\n",
      "3. Serratus Anterior Muscle: This muscle is located on the sides of the chest and helps to stabilize the shoulder blades and move the arms.\n",
      "4. Rib Cage: The rib cage is made up of 12 pairs of ribs that provide protection for the organs in the chest area.\n",
      "\n",
      "So, there are 4 parts to the human chest: Pectoralis Major Muscle, Pectoralis Minor Muscle, Serratus Anterior Muscle, and Rib Cage.Evaluation output: {'reasoning': 'Rating: [[8]]\\n\\nIn this response, the AI assistant provided accurate and factual information regarding the number of parts in the human chest. The assistant correctly identified and explained four distinct muscles located in the chest area, which are the pectoralis major muscle, pectoralis minor muscle, serratus anterior muscle, and rib cage. These muscles play important roles in shoulder movement, breathing, and protecting the organs in the chest area.\\n\\nThe response was well-structured and easy to understand, with each part of the chest being clearly defined and explained. The assistant also provided a brief explanation for each muscle, which helped to further clarify their functions.\\n\\nOverall, this response demonstrated a high level of correctness and accuracy, making it an excellent evaluation.', 'score': 8}\n",
      "\n",
      "[QUESTION] how many parts has the human chest?\n",
      "[SCORE] 8\n",
      "O Modelo demorou 63.2 segundos a gerar as respostas.\n"
     ]
    }
   ],
   "source": [
    "#Avaliação do Llama2 segundo o Tempo, a Precisão e a Accuracy.\n",
    "inicio = time.time()\n",
    "db = load_documents_into_database(\"llama2\",\"nomic-embed-text\",\"../Final PDF Files\",True)\n",
    "evaluate_llama2(\"llama2\",db)\n",
    "fim = time.time()\n",
    "print(\"O Modelo demorou \" + str(round((fim-inicio),2)) + \" segundos a gerar as respostas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zephyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents\n",
      "Loading .pdf files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:03<00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading .md files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings and loading documents into Chroma\n",
      "\n",
      "[INFO] Evaluating model:  zephyr\n",
      "There are several distinct anatomical structures that make up the human chest, as described in scientific research and anatomical sources. These include:\n",
      "\n",
      "1. Thoracic Cage: This is a bony structure that protects and supports the heart, lungs, and other internal organs. It is made up of 12 pairs of ribs and the breastbone (sternum).\n",
      "\n",
      "2. Ribcage: The ribcage consists of the thoracic cage and the 12 pairs of ribs that attach to it. It provides protection for the internal organs and helps with respiration by facilitating the expansion and contraction of the lungs during breathing.\n",
      "\n",
      "3. Intercostal Muscles: These are a group of muscles located between each pair of ribs, which facilitate movement and expansion of the chest during respiration.\n",
      "\n",
      "4. Diaphragm: This is a large muscle that separates the chest from the abdomen. It plays a crucial role in breathing by contracting and flattening to increase the volume of the chest cavity during inhalation.\n",
      "\n",
      "5. Lungs: The lungs are a pair of organs located within the chest cavity, responsible for respiration and gas exchange. They are made up of smaller structures called bronchioles, alveoli, and capillaries.\n",
      "\n",
      "6. Heart: Located behind the breastbone, the heart is a muscular organ that pumps blood throughout the body. It is divided into four chambers: the right atrium, right ventricle, left atrium, and left ventricle.\n",
      "\n",
      "7. Esophagus: This is a muscular tube that connects the throat to the stomach, allowing for the passage of food and drink into the digestive system.\n",
      "\n",
      "8. Trachea (Windpipe): This is a tube-like structure that connects the mouth and nose to the bronchioles of the lungs, facilitating the passage of air during breathing.\n",
      "\n",
      "9. Bronchioles: These are smaller tubes within the lungs that branch off from the trachea and lead to the alveoli, where gas exchange occurs.\n",
      "\n",
      "10. Alveoli: These are small sacs located at the end of the bronchioles in the lungs, where oxygen enters the bloodstream during respiration and carbon dioxide is released.\n",
      "\n",
      "In summary, there are several distinct anatomical structures that make up the human chest, each with a specific function and role in the body's overall physiology.ValueError: Invalid output: Explanation: The response provided by the AI assistant is accurate and factual. It lists all the significant anatomical structures that make up the human chest, along with a brief description of each structure's function. The explanation is clear, concise, and easy to understand, providing a detailed overview of the human chest anatomy.\n",
      "\n",
      "Rating: [10]. Output must contain a double bracketed string                 with the verdict between 1 and 10.\n",
      "Evaluation output: Invalid output: Explanation: The response provided by the AI assistant is accurate and factual. It lists all the significant anatomical structures that make up the human chest, along with a brief description of each structure's function. The explanation is clear, concise, and easy to understand, providing a detailed overview of the human chest anatomy.\n",
      "\n",
      "Rating: [10]. Output must contain a double bracketed string                 with the verdict between 1 and 10.\n",
      "\n",
      "[QUESTION] how many parts has the human chest?\n",
      "[SCORE] 10\n",
      "O Modelo demorou 89.32 segundos a gerar as respostas.\n"
     ]
    }
   ],
   "source": [
    "#Avaliação do Zephyr segundo o Tempo, a Precisão e a Accuracy.\n",
    "inicio = time.time()\n",
    "db = load_documents_into_database(\"zephyr\",\"nomic-embed-text\",\"../Final PDF Files\",True)\n",
    "evaluate_zephyr(\"zephyr\",db)\n",
    "fim = time.time()\n",
    "print(\"O Modelo demorou \" + str(round((fim-inicio),2)) + \" segundos a gerar as respostas.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataMining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
